{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load Dataset & Informasi Awal"
      ],
      "metadata": {
        "id": "fgVTATgtmkYP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk6RrRjPhz3-"
      },
      "outputs": [],
      "source": [
        "# Import library utama\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data science/UAS/Recipe Reviews and User Feedback Dataset.csv')\n",
        "\n",
        "# Tampilkan 5 data pertama\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informasi struktur dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "tZPpDOk8myEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah baris dan kolom\n",
        "print(\"Jumlah baris:\", df.shape[0])\n",
        "print(\"Jumlah kolom:\", df.shape[1])"
      ],
      "metadata": {
        "id": "r0R0CBczm0i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ppkyZI_wm3dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek jumlah data duplikat\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "rbQgULsVm7a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['stars'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "Ikz5my47nkEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['stars'].value_counts(normalize=True).sort_index() * 100"
      ],
      "metadata": {
        "id": "DLQWsQ_xnm5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "rbZyRuuqnCLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(x='stars', data=df)\n",
        "plt.title('Distribusi Rating Bintang')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Jumlah Komentar')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KZ3x0OlpnFKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df['text'].astype(str).apply(len)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['text_length'], bins=50, kde=True)\n",
        "plt.title('Distribusi Panjang Teks Ulasan')\n",
        "plt.xlabel('Jumlah Karakter')\n",
        "plt.ylabel('Frekuensi')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "icXFP8S0nOzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text_all = ' '.join(df['text'].dropna())\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white'\n",
        ").generate(text_all)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('WordCloud Ulasan Resep Masakan')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9PGGMOP9nuYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.DATA PREPARATION"
      ],
      "metadata": {
        "id": "x2hkM-6VqfPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Cleaning\n",
        "\n",
        "# Menghapus data dengan text kosong\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "print(\"Jumlah data setelah cleaning:\", df.shape[0])\n"
      ],
      "metadata": {
        "id": "_cGccty3rWgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])\n"
      ],
      "metadata": {
        "id": "ZFbA4AZfrtET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Labeling Sentimen dari Rating (stars)\n",
        "\n",
        "#Dataset tidak memiliki label sentimen eksplisit, sehingga dilakukan konversi rating bintang menjadi label sentimen.\n",
        "\n",
        "# Labeling sentimen dari stars\n",
        "def label_sentiment(star):\n",
        "    if star >= 4:\n",
        "        return 1   # Positif\n",
        "    else:\n",
        "        return 0   # Negatif\n",
        "\n",
        "df['sentiment'] = df['stars'].apply(label_sentiment)\n"
      ],
      "metadata": {
        "id": "V2gefrHCr15p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text Preprocessing\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].astype(str).apply(clean_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "z8Ft7-kpsEdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "oUNR_Ades1V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Extraction – TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=5,\n",
        "    max_df=0.9\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n"
      ],
      "metadata": {
        "id": "sGAQp9s5sdVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tokenization & Padding (Untuk LSTM)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_words = 8000\n",
        "max_len = 80\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_train),\n",
        "    maxlen=max_len,\n",
        "    padding='post'\n",
        ")\n",
        "\n",
        "X_test_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_test),\n",
        "    maxlen=max_len,\n",
        "    padding='post'\n",
        ")\n",
        "\n",
        "vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n"
      ],
      "metadata": {
        "id": "Wmk0hze2sl0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Class Weighting (Imbalanced Data)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(classes, weights))\n",
        "class_weights\n"
      ],
      "metadata": {
        "id": "O3FkeZfrs8XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Modeling"
      ],
      "metadata": {
        "id": "LPgn3hAd9kdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6.1 Model 1 – Baseline Model (Logistic Regression)**"
      ],
      "metadata": {
        "id": "1PFGLIY19Plh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter**\n",
        "\n",
        "- C: 1.0\n",
        "- solver: lbfgs\n",
        "- max_iter: 1000\n",
        "- class_weight: balanced"
      ],
      "metadata": {
        "id": "_S8L3tTt7AoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Implementasi\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg_model = LogisticRegression(\n",
        "    C=2.0,\n",
        "    max_iter=2000,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "logreg_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_logreg = logreg_model.predict(X_test_tfidf)\n"
      ],
      "metadata": {
        "id": "Nseo-ikV7E_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6.2 Model 2 – Advanced Machine Learning Model (Random Forest)**"
      ],
      "metadata": {
        "id": "lL1vgzer7TiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter**\n",
        "- n_estimators: 200\n",
        "- max_depth: 20\n",
        "- min_samples_split: 5\n",
        "- class_weight: balanced\n",
        "- random_state: 42\n"
      ],
      "metadata": {
        "id": "bOmbyq5s7avx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Implementasi\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=25,\n",
        "    min_samples_split=10,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_tfidf)\n"
      ],
      "metadata": {
        "id": "N9AClFoK7nWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6.3 Model 3 – Deep Learning Model (LSTM)**"
      ],
      "metadata": {
        "id": "LUYupMsP8XD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arsitektur Model**\n",
        "1. Embedding Layer (vocab_size, 128)\n",
        "2. LSTM Layer (128 units, return_sequences=False)\n",
        "3. Dropout (0.5)\n",
        "4. Dense Layer (64 units, ReLU)\n",
        "5. Dropout (0.3)\n",
        "6. Output Layer (Softmax)\n"
      ],
      "metadata": {
        "id": "VG1VaoVt8kCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input & Preprocessing**\n",
        "- Input shape: (sequence_length,)\n",
        "- Preprocessing khusus:\n",
        "  - Tokenization\n",
        "  - Padding sequences\n",
        "  - Label encoding target"
      ],
      "metadata": {
        "id": "vzu3Rq5h8t6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5HAJk9v386UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Implementasi\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "vocab_size = min(10000, len(tokenizer.word_index) + 1)\n",
        "max_len = X_train_seq.shape[1]\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=128,\n",
        "        input_length=max_len\n",
        "    ),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.4),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "lstm_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = lstm_model.fit(\n",
        "    X_train_seq,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DJIiNzNl8e3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Summary\n",
        "\n",
        "lstm_model.summary()\n"
      ],
      "metadata": {
        "id": "tRYp29-ICNjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Evaluation"
      ],
      "metadata": {
        "id": "jzMCQ-7-ITsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")"
      ],
      "metadata": {
        "id": "lfHwrfV5IWen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 -Logistic Regression"
      ],
      "metadata": {
        "id": "K7IJTdaLJYVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrik Evaluasi\n",
        "\n",
        "acc_lr = accuracy_score(y_test, y_pred_logreg)\n",
        "prec_lr = precision_score(y_test, y_pred_logreg, average='weighted')\n",
        "rec_lr = recall_score(y_test, y_pred_logreg, average='weighted')\n",
        "f1_lr = f1_score(y_test, y_pred_logreg, average='weighted')\n",
        "\n",
        "print(\"=== Logistic Regression ===\")\n",
        "print(f\"Accuracy  : {acc_lr:.4f}\")\n",
        "print(f\"Precision : {prec_lr:.4f}\")\n",
        "print(f\"Recall    : {rec_lr:.4f}\")\n",
        "print(f\"F1-Score  : {f1_lr:.4f}\")\n"
      ],
      "metadata": {
        "id": "m7FCWPUIIZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion Matrix\n",
        "\n",
        "cm_lr = confusion_matrix(y_test, y_pred_logreg)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pe9o3xlNJqKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classification Report\n",
        "\n",
        "print(classification_report(y_test, y_pred_logreg))\n"
      ],
      "metadata": {
        "id": "R0Z_AqPZJzuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 – Random Forest"
      ],
      "metadata": {
        "id": "QITLaIfuKNYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrik Evaluasi\n",
        "\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "prec_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "rec_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(\"=== Random Forest ===\")\n",
        "print(f\"Accuracy  : {acc_rf:.4f}\")\n",
        "print(f\"Precision : {prec_rf:.4f}\")\n",
        "print(f\"Recall    : {rec_rf:.4f}\")\n",
        "print(f\"F1-Score  : {f1_rf:.4f}\")\n"
      ],
      "metadata": {
        "id": "BK5zxOxpKS7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion Matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3Lo9LtsQKyN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classification Report\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "uoj1T5KyK9dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 – LSTM"
      ],
      "metadata": {
        "id": "YsAGczgFLDvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lstm_prob = lstm_model.predict(X_test_seq)\n",
        "y_pred_lstm = (y_pred_lstm_prob > 0.5).astype(int).ravel()"
      ],
      "metadata": {
        "id": "1UEjzqK2LF-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrik Evaluasi\n",
        "\n",
        "acc_lstm = accuracy_score(y_test, y_pred_lstm)\n",
        "prec_lstm = precision_score(y_test, y_pred_lstm, average='weighted')\n",
        "rec_lstm = recall_score(y_test, y_pred_lstm, average='weighted')\n",
        "f1_lstm = f1_score(y_test, y_pred_lstm, average='weighted')\n",
        "\n",
        "print(\"=== LSTM ===\")\n",
        "print(f\"Accuracy  : {acc_lstm:.4f}\")\n",
        "print(f\"Precision : {prec_lstm:.4f}\")\n",
        "print(f\"Recall    : {rec_lstm:.4f}\")\n",
        "print(f\"F1-Score  : {f1_lstm:.4f}\")"
      ],
      "metadata": {
        "id": "g81s72WJLWNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion Matrix\n",
        "cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Oranges')\n",
        "plt.title(\"Confusion Matrix - LSTM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q3J6T6S2Lg_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classification Report\n",
        "print(classification_report(y_test, y_pred_lstm))\n"
      ],
      "metadata": {
        "id": "SfTps4tvLjho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training History LSTM"
      ],
      "metadata": {
        "id": "vNJEG5H9L6O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss (LSTM)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ti2DugeNL8uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Accuracy\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy (LSTM)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uWyrl5rNME__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tabel Perbandingan Model (Output Gambar)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data tabel (pastikan variabel ini SUDAH ADA dari evaluasi sebelumnya)\n",
        "models = [\"Logistic Regression\", \"Random Forest\", \"LSTM\"]\n",
        "accuracy = [acc_lr, acc_rf, acc_lstm]\n",
        "precision = [prec_lr, prec_rf, prec_lstm]\n",
        "recall = [rec_lr, rec_rf, acc_lstm]\n",
        "f1 = [f1_lr, f1_rf, f1_lstm]\n",
        "\n",
        "# Membuat figure\n",
        "fig, ax = plt.subplots(figsize=(9, 3))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "# Isi tabel\n",
        "table_data = [\n",
        "    [models[i],\n",
        "     f\"{accuracy[i]:.3f}\",\n",
        "     f\"{precision[i]:.3f}\",\n",
        "     f\"{recall[i]:.3f}\",\n",
        "     f\"{f1[i]:.3f}\"]\n",
        "    for i in range(len(models))\n",
        "]\n",
        "\n",
        "columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
        "\n",
        "table = ax.table(\n",
        "    cellText=table_data,\n",
        "    colLabels=columns,\n",
        "    loc='center',\n",
        "    cellLoc='center'\n",
        ")\n",
        "\n",
        "# Styling tabel\n",
        "table.scale(1, 1.6)\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(11)\n",
        "\n",
        "plt.title(\"Perbandingan Performa Model\", fontsize=13, pad=10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WxW3ur6QMO72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Meyimpan Model"
      ],
      "metadata": {
        "id": "rI9BdZ-ltUCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simpan Model Logistic Regression\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(logreg_model, \"model_baseline.pkl\")\n",
        "\n",
        "print(\"Logistic Regression berhasil disimpan model_baseline.pkl\")\n"
      ],
      "metadata": {
        "id": "K95wDAnFtW4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simpan Model Random Forest\n",
        "\n",
        "joblib.dump(rf_model, \"model_rf.pkl\")\n",
        "\n",
        "print(\"Random Forest berhasil disimpan model_rf.pkl\")\n"
      ],
      "metadata": {
        "id": "lSPCeOzNtZsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simpan Model LSTM\n",
        "\n",
        "lstm_model.save(\"model_lstm.keras\")\n",
        "\n",
        "print(\"LSTM berhasil disimpan model_lstm.keras\")\n"
      ],
      "metadata": {
        "id": "fQ6KftJuta_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}